{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d44836",
   "metadata": {},
   "source": [
    "# Actividad Final — Métodos Estadísticos Computacionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218781e",
   "metadata": {},
   "source": [
    "\n",
    "**Temas:** Diseño de experimentos computacional · Manual de software · Protocolo de presentación final.  \n",
    "Este notebook reproduce el flujo de trabajo del informe (**prueba de hipótesis, regresión lineal y logística**) y añade: **regularización**, **tuning**, **curva de aprendizaje**, **mini-dashboard JupyterDash** y **exportación de `app.py`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb84fdf",
   "metadata": {},
   "source": [
    "## 0) Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d55df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Si lo necesitas, instala dependencias desde el proyecto:\n",
    "# %pip install -r ../requirements-win.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0f88c",
   "metadata": {},
   "source": [
    "## 1) Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "plt.rcParams['figure.figsize']=(6,4)\n",
    "plt.rcParams['axes.grid']=True\n",
    "\n",
    "df = pd.read_csv(Path('../data/students_synth.csv'))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad658553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e7cec",
   "metadata": {},
   "source": [
    "## 2) EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bddc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(df['puntuacion'], bins=20, alpha=0.7); plt.title('Distribución de puntuación'); plt.show()\n",
    "\n",
    "for m in ['A','B']:\n",
    "    plt.hist(df.loc[df['metodo']==m,'puntuacion'], bins=20, alpha=0.6, label=f'Método {m}')\n",
    "plt.title('Puntuación por método'); plt.legend(); plt.show()\n",
    "\n",
    "plt.scatter(df['horas_estudio'], df['puntuacion'], alpha=0.5)\n",
    "plt.title('Horas de estudio vs Puntuación'); plt.xlabel('horas_estudio'); plt.ylabel('puntuacion'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b7e43",
   "metadata": {},
   "source": [
    "## 3) Prueba de hipótesis (t de Welch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28164f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stats\n",
    "pA = df.loc[df['metodo']=='A','puntuacion']\n",
    "pB = df.loc[df['metodo']=='B','puntuacion']\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(pA, pB, equal_var=False)\n",
    "print(f\"Media A={pA.mean():.2f}  Media B={pB.mean():.2f}\\nt={t_stat:.3f}  p={p_value:.4f}\")\n",
    "print(\"Conclusión:\", \"Rechazo H0 (difieren)\" if p_value<0.05 else \"No rechazo H0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aef266",
   "metadata": {},
   "source": [
    "## 4) Regresión lineal y regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4463d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_lin = df[['horas_estudio','horas_suenio','gpa_previo']]\n",
    "y_lin = df['puntuacion']\n",
    "Xtr, Xte, ytr, yte = train_test_split(X_lin, y_lin, test_size=0.3, random_state=42)\n",
    "\n",
    "lin = LinearRegression().fit(Xtr, ytr)\n",
    "yhat = lin.predict(Xte)\n",
    "print(\"Coef:\", dict(zip(X_lin.columns, np.round(lin.coef_,3))), \"Intercepto:\", round(lin.intercept_,3))\n",
    "print(\"MSE:\", round(mean_squared_error(yte,yhat),2), \"R²:\", round(r2_score(yte,yhat),3))\n",
    "\n",
    "alphas = np.logspace(-3,3,21)\n",
    "ridge = RidgeCV(alphas=alphas, cv=5).fit(Xtr, ytr)\n",
    "lasso = LassoCV(cv=5, random_state=42, max_iter=5000).fit(Xtr, ytr)\n",
    "print(\"Ridge α*=\", ridge.alpha_, \"R²(test)=\", round(ridge.score(Xte,yte),3))\n",
    "print(\"Lasso α*=\", round(lasso.alpha_,4), \"R²(test)=\", round(lasso.score(Xte,yte),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ab5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(yte, yhat, alpha=0.6); \n",
    "mn, mx = yte.min(), yte.max()\n",
    "plt.plot([mn,mx],[mn,mx],'k--'); plt.title('Lineal — Real vs Predicho'); plt.xlabel('Real'); plt.ylabel('Predicho'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e8586",
   "metadata": {},
   "source": [
    "## 5) Regresión logística (clasificación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e209402",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "\n",
    "X_log = pd.concat([df[['horas_estudio','horas_suenio','gpa_previo']], pd.get_dummies(df['metodo'], drop_first=True)], axis=1)\n",
    "y_log = df['aprueba']\n",
    "\n",
    "Xtr_l, Xte_l, ytr_l, yte_l = train_test_split(X_log, y_log, test_size=0.3, random_state=42, stratify=y_log)\n",
    "scaler = StandardScaler()\n",
    "Xtr_l_sc = scaler.fit_transform(Xtr_l)\n",
    "Xte_l_sc = scaler.transform(Xte_l)\n",
    "\n",
    "logit = LogisticRegression(solver='liblinear', max_iter=1500, C=1.0).fit(Xtr_l_sc, ytr_l)\n",
    "proba = logit.predict_proba(Xte_l_sc)[:,1]\n",
    "yhat = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(dict(\n",
    "    accuracy = round(accuracy_score(yte_l, yhat),3),\n",
    "    precision = round(precision_score(yte_l, yhat, zero_division=0),3),\n",
    "    recall = round(recall_score(yte_l, yhat),3),\n",
    "    f1 = round(f1_score(yte_l, yhat),3),\n",
    "    roc_auc = round(roc_auc_score(yte_l, proba),3),\n",
    "    cm = confusion_matrix(yte_l, yhat)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpr,tpr,thr = roc_curve(yte_l, proba)\n",
    "plt.plot(fpr,tpr,label=f\"AUC={roc_auc_score(yte_l,proba):.3f}\")\n",
    "plt.plot([0,1],[0,1],'k--'); plt.legend(); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Logística'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30516c9",
   "metadata": {},
   "source": [
    "### Tuning de hiperparámetros (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d42fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'C': np.logspace(-3,3,13)}\n",
    "gcv = GridSearchCV(LogisticRegression(solver='liblinear', max_iter=2000), grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "gcv.fit(Xtr_l_sc, ytr_l)\n",
    "best = gcv.best_estimator_\n",
    "print(\"Mejor C:\", gcv.best_params_, \"ROC_AUC(CV):\", round(gcv.best_score_,3))\n",
    "print(\"ROC_AUC(test):\", round(roc_auc_score(yte_l, best.predict_proba(Xte_l_sc)[:,1]),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde7112",
   "metadata": {},
   "source": [
    "### Curva de aprendizaje (diseño experimental básico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "sizes, tr_sc, te_sc = learning_curve(LinearRegression(), X_lin, y_lin, cv=5, train_sizes=np.linspace(0.1,1.0,5), scoring='r2', n_jobs=-1)\n",
    "plt.plot(sizes, tr_sc.mean(axis=1),'o-',label='Train R²')\n",
    "plt.plot(sizes, te_sc.mean(axis=1),'o-',label='CV R²')\n",
    "plt.legend(); plt.xlabel('Tamaño de entrenamiento'); plt.ylabel('R²'); plt.title('Curva de aprendizaje'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825dff8",
   "metadata": {},
   "source": [
    "## 6) Mini-dashboard con JupyterDash (inline en notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae97dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html, Input, Output, dash_table\n",
    "import plotly.express as px\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = html.Div([\n",
    "    html.H3(\"Explorador — Estudiantes\"),\n",
    "    html.Div([\n",
    "        html.Label(\"X\"),\n",
    "        dcc.Dropdown(id=\"x\", options=[{\"label\":c,\"value\":c} for c in [\"horas_estudio\",\"horas_suenio\",\"gpa_previo\",\"indice_socioeco\"]], value=\"horas_estudio\"),\n",
    "        html.Label(\"Y\"),\n",
    "        dcc.Dropdown(id=\"y\", options=[{\"label\":\"puntuacion\",\"value\":\"puntuacion\"}], value=\"puntuacion\"),\n",
    "        html.Label(\"Método\"),\n",
    "        dcc.Dropdown(id=\"m\", options=[{\"label\":\"Todos\",\"value\":\"all\"},{\"label\":\"A\",\"value\":\"A\"},{\"label\":\"B\",\"value\":\"B\"}], value=\"all\"),\n",
    "    ], style={\"display\":\"flex\",\"gap\":\"12px\",\"flexWrap\":\"wrap\"}),\n",
    "    dcc.Graph(id=\"g\"),\n",
    "    dash_table.DataTable(id=\"tbl\", data=df.head(50).to_dict(\"records\"),\n",
    "                         columns=[{\"name\":c,\"id\":c} for c in df.columns],\n",
    "                         page_size=10, sort_action=\"native\", filter_action=\"native\", style_table={\"overflowX\":\"auto\"})\n",
    "])\n",
    "\n",
    "@app.callback(Output(\"g\",\"figure\"), Input(\"x\",\"value\"), Input(\"y\",\"value\"), Input(\"m\",\"value\"))\n",
    "def _upd(x,y,m):\n",
    "    dff = df.copy()\n",
    "    if m != \"all\":\n",
    "        dff = dff[dff[\"metodo\"]==m]\n",
    "    return px.scatter(dff, x=x, y=y, color=\"aprueba\", trendline=\"ols\")\n",
    "\n",
    "print(\"Para ejecutarlo inline descomenta la siguiente línea:\")\n",
    "# app.run_server(mode='inline', port=8051, debug=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f393ab",
   "metadata": {},
   "source": [
    "## 7) Exportar/actualizar `app.py` (para despliegue externo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "code = Path('../app.py').read_text(encoding='utf-8')\n",
    "Path('../app.py').write_text(code, encoding='utf-8')\n",
    "print(\"Se dejó listo ../app.py para desplegar en Render o HF Spaces.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e51f2",
   "metadata": {},
   "source": [
    "## 8) Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251b535",
   "metadata": {},
   "source": [
    "\n",
    "- La prueba de hipótesis compara métodos (A/B) con la t de Welch.\n",
    "- La regresión lineal explica la variación de la puntuación con estudio/sueño/GPA.\n",
    "- La logística clasifica aprobación; ajustamos el umbral según objetivo.\n",
    "- Regularización y *grid search* estabilizan modelos y controlan sobreajuste.\n",
    "- El mini-dashboard permite narrativa y exploración interactiva; `app.py` habilita despliegue externo.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
